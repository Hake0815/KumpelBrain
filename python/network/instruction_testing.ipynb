{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d511ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import instruction_test_data as itd\n",
    "import numpy as np\n",
    "import card_embedding as ce\n",
    "import nesting\n",
    "from multi_head_attention import MultiHeadAttention\n",
    "from positional_embedding import PositionalEmbedding\n",
    "torch.manual_seed(1)\n",
    "\n",
    "d=8\n",
    "shared_embedding_holder = ce.SharedEmbeddingHolder(d, device='cuda')\n",
    "positional_embedding = PositionalEmbedding(d, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46090cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.6120,  3.2177,  4.4789,  1.9952,  0.7815, -7.9421, -9.0347,  8.1897],\n",
      "        [ 2.2885, -2.0347, -2.3284,  0.6772, -9.2289, -9.8569, -3.0202,  0.2285],\n",
      "        [ 0.1685,  0.2371,  0.5718,  1.6196,  1.0329,  0.2250,  2.0036,  0.9421],\n",
      "        [ 0.1818,  1.4895,  0.3771,  1.5049,  1.0562,  0.0494,  0.0668,  0.8926],\n",
      "        [-3.0103, -0.3263, -2.4020, -2.2322, -0.9752, -0.1198, -7.6821,  1.9554]],\n",
      "       device='cuda:0', grad_fn=<SumBackwardAutogradNestedTensor1>)\n",
      "torch.Size([5, 8])\n"
     ]
    }
   ],
   "source": [
    "instruction_embedding = ce.InstructionEmbedding(shared_embedding_holder, d, device=\"cuda\")\n",
    "\n",
    "instruction_embeddings = instruction_embedding(itd.instructions_batch)\n",
    "print(instruction_embeddings)\n",
    "print(instruction_embeddings.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "class InstructionDataEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        shared_embedding_holder: ce.SharedEmbeddingHolder,\n",
    "        dimension_out: int,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        self.factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "        self.dimension_out = dimension_out\n",
    "        self.attack_data_embedding = ce.AttackDataEmbedding(\n",
    "            dimension_out, **self.factory_kwargs\n",
    "        )\n",
    "        self.discard_data_embedding = ce.DiscardDataEmbedding(\n",
    "            dimension_out, **self.factory_kwargs\n",
    "        )\n",
    "        self.card_amount_data_embedding = ce.CardAmountDataEmbedding(\n",
    "            shared_embedding_holder, dimension_out, **self.factory_kwargs\n",
    "        )\n",
    "        self.return_to_deck_type_data_embedding = ce.ReturnToDeckTypeDataEmbedding(\n",
    "            shared_embedding_holder, dimension_out, **self.factory_kwargs\n",
    "        )\n",
    "        self.filter_embedding = ce.FilterEmbedding(\n",
    "            shared_embedding_holder, dimension_out, **self.factory_kwargs\n",
    "        )\n",
    "        self.player_target_data_embedding = ce.PlayerTargetDataEmbedding(\n",
    "            shared_embedding_holder, dimension_out, **self.factory_kwargs\n",
    "        )\n",
    "        self.instruction_data_type_embedding = nn.Embedding(\n",
    "            6, dimension_out, padding_idx=0, **self.factory_kwargs\n",
    "        )\n",
    "        self.data_multi_head_attention = MultiHeadAttention(\n",
    "            dimension_out,\n",
    "            dimension_out,\n",
    "            dimension_out,\n",
    "            max(dimension_out // 16, 4),\n",
    "            4,\n",
    "            **self.factory_kwargs,\n",
    "        )\n",
    "        self.position_embedding = shared_embedding_holder.position_embedding\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        instruction_indices,\n",
    "        instruction_data_types,\n",
    "        instruction_data_type_indices,\n",
    "        instruction_data,\n",
    "        instruction_data_indices,\n",
    "        batch_size: int,\n",
    "    ) -> torch.Tensor:\n",
    "        instruction_data_type_embeddings = self.instruction_data_type_embedding(\n",
    "            instruction_data_types\n",
    "        )\n",
    "        if instruction_data[0]:\n",
    "            attack_data_embeddings = self.attack_data_embedding(\n",
    "                torch.stack(instruction_data[0])\n",
    "            )\n",
    "        else:\n",
    "            attack_data_embeddings = []\n",
    "        if instruction_data[1]:\n",
    "            discard_data_embeddings = self.discard_data_embedding(\n",
    "                torch.tensor(instruction_data[1], **self.factory_kwargs)\n",
    "            )\n",
    "        else:\n",
    "            discard_data_embeddings = []\n",
    "        if instruction_data[2]:\n",
    "            card_amount_data_embeddings = self.card_amount_data_embedding(\n",
    "                torch.stack(instruction_data[2])\n",
    "            )\n",
    "        else:\n",
    "            card_amount_data_embeddings = []\n",
    "        if instruction_data[3]:\n",
    "            return_to_deck_type_data_embeddings = self.return_to_deck_type_data_embedding(\n",
    "                torch.stack(instruction_data[3])\n",
    "            )\n",
    "        else:\n",
    "            return_to_deck_type_data_embeddings = []\n",
    "        if instruction_data[4]:\n",
    "            filter_embeddings = self.filter_embedding(instruction_data[4])\n",
    "        else:\n",
    "            filter_embeddings = []\n",
    "        if instruction_data[5]:\n",
    "            player_target_data_embeddings = self.player_target_data_embedding(\n",
    "                torch.tensor(instruction_data[5], **self.factory_kwargs)\n",
    "            )\n",
    "        else:\n",
    "            player_target_data_embeddings = []\n",
    "        # return attack_data_embeddings, discard_data_embeddings, card_amount_data_embeddings, return_to_deck_type_data_embeddings, filter_embeddings, player_target_data_embeddings\n",
    "\n",
    "        sorted_data = self.sort_tensors_with_respect_to_index(\n",
    "            (\n",
    "                attack_data_embeddings,\n",
    "                discard_data_embeddings,\n",
    "                card_amount_data_embeddings,\n",
    "                return_to_deck_type_data_embeddings,\n",
    "                filter_embeddings,\n",
    "                player_target_data_embeddings,\n",
    "            ),\n",
    "            instruction_data_indices,\n",
    "        )\n",
    "        return sorted_data + instruction_data_type_embeddings\n",
    "\n",
    "    def sort_tensors_with_respect_to_index(self, tensors, indices):\n",
    "        return torch.stack(\n",
    "            [\n",
    "                tensor\n",
    "                for _, tensor in sorted(\n",
    "                    zip(\n",
    "                        chain.from_iterable(indices),\n",
    "                        chain.from_iterable(tensors),\n",
    "                    ),\n",
    "                    key=lambda pair: pair[0],\n",
    "                )\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "600f2b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([], [], [(0, 0, 0), (1, 0, 0), (2, 0, 0), (2, 1, 0)], [], [], [])\n",
      "([], [], tensor([[ 0.2699,  1.5510, -1.4474, -1.6604,  1.2613,  0.2293, -0.8266, -0.2678],\n",
      "        [ 0.2699,  1.5510, -1.4474, -1.6604,  1.2613,  0.2293, -0.8266, -0.2678],\n",
      "        [ 0.3690, -0.1970, -0.0166,  2.0454, -0.3100,  1.0262,  0.3317,  2.1031],\n",
      "        [ 0.2699,  1.5510, -1.4474, -1.6604,  1.2613,  0.2293, -0.8266, -0.2678]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), [], [], [])\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    condition_types,\n",
    "    condition_indices,\n",
    "    instruction_data_types,\n",
    "    instruction_data_type_indices,\n",
    "    instruction_data,\n",
    "    instruction_data_indices,\n",
    ") = nesting.flatten_instructions(\"ConditionType\", itd.conditions_batch, device=\"cuda\")\n",
    "print(instruction_data_indices)\n",
    "instruction_data_embedding = InstructionDataEmbedding(shared_embedding_holder, d, device=\"cuda\")\n",
    "tensors = instruction_data_embedding(\n",
    "    condition_indices,\n",
    "    instruction_data_types,\n",
    "    instruction_data_type_indices,\n",
    "    instruction_data,\n",
    "    instruction_data_indices,\n",
    "    len(itd.conditions_batch)\n",
    ")\n",
    "print(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8778d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2699,  1.5510, -1.4474, -1.6604,  1.2613,  0.2293, -0.8266, -0.2678],\n",
      "       device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "tensor([ 0.2699,  1.5510, -1.4474, -1.6604,  1.2613,  0.2293, -0.8266, -0.2678],\n",
      "       device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "tensor([ 0.3690, -0.1970, -0.0166,  2.0454, -0.3100,  1.0262,  0.3317,  2.1031],\n",
      "       device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "tensor([ 0.2699,  1.5510, -1.4474, -1.6604,  1.2613,  0.2293, -0.8266, -0.2678],\n",
      "       device='cuda:0', grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _, tensor in sorted(\n",
    "                    zip(\n",
    "                        chain.from_iterable(instruction_data_type_indices),\n",
    "                        chain.from_iterable(tensors),\n",
    "                    ),\n",
    "                    key=lambda pair: pair[0],\n",
    "                ):\n",
    "                print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6419342d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m condition_embedding = ce.ConditionEmbedding(shared_embedding_holder, d, device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m condition_embeddings = \u001b[43mcondition_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconditions_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(condition_embeddings)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(condition_embeddings.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai/KumpelBrain/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai/KumpelBrain/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai/KumpelBrain/python/network/card_embedding.py:637\u001b[39m, in \u001b[36mConditionEmbedding.forward\u001b[39m\u001b[34m(self, conditions_batch)\u001b[39m\n\u001b[32m    626\u001b[39m (\n\u001b[32m    627\u001b[39m     condition_types,\n\u001b[32m    628\u001b[39m     condition_indices,\n\u001b[32m   (...)\u001b[39m\u001b[32m    634\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mConditionType\u001b[39m\u001b[33m\"\u001b[39m, conditions_batch, **\u001b[38;5;28mself\u001b[39m.factory_kwargs\n\u001b[32m    635\u001b[39m )\n\u001b[32m    636\u001b[39m instruction_type_embeddings = \u001b[38;5;28mself\u001b[39m.condition_type_embedding(condition_types)\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m data_tensors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minstruction_data_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcondition_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstruction_data_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstruction_data_type_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstruction_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstruction_data_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m condition_embeddings = embed_instruction_data(\n\u001b[32m    647\u001b[39m     \u001b[38;5;28mself\u001b[39m.data_multi_head_attention,\n\u001b[32m    648\u001b[39m     condition_indices,\n\u001b[32m   (...)\u001b[39m\u001b[32m    651\u001b[39m     data_tensors,\n\u001b[32m    652\u001b[39m )\n\u001b[32m    654\u001b[39m batched_conditions = batch_instructions(\n\u001b[32m    655\u001b[39m     \u001b[38;5;28mself\u001b[39m.position_embedding, condition_indices, condition_embeddings, batch_size\n\u001b[32m    656\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai/KumpelBrain/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai/KumpelBrain/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ai/KumpelBrain/python/network/card_embedding.py:545\u001b[39m, in \u001b[36mInstructionDataEmbedding.forward\u001b[39m\u001b[34m(self, instruction_indices, instruction_data_types, instruction_data_type_indices, instruction_data, instruction_data_indices, batch_size)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    533\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    534\u001b[39m     instruction_indices,\n\u001b[32m   (...)\u001b[39m\u001b[32m    539\u001b[39m     batch_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    540\u001b[39m ) -> torch.Tensor:\n\u001b[32m    541\u001b[39m     instruction_data_type_embeddings = \u001b[38;5;28mself\u001b[39m.instruction_data_type_embedding(\n\u001b[32m    542\u001b[39m         instruction_data_types\n\u001b[32m    543\u001b[39m     )\n\u001b[32m    544\u001b[39m     attack_data_embeddings = \u001b[38;5;28mself\u001b[39m.attack_data_embedding(\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction_data\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    546\u001b[39m     )\n\u001b[32m    547\u001b[39m     discard_data_embeddings = \u001b[38;5;28mself\u001b[39m.discard_data_embedding(\n\u001b[32m    548\u001b[39m         torch.tensor(instruction_data[\u001b[32m1\u001b[39m], **\u001b[38;5;28mself\u001b[39m.factory_kwargs)\n\u001b[32m    549\u001b[39m     )\n\u001b[32m    550\u001b[39m     card_amount_data_embeddings = \u001b[38;5;28mself\u001b[39m.card_amount_data_embedding(\n\u001b[32m    551\u001b[39m         torch.stack(instruction_data[\u001b[32m2\u001b[39m])\n\u001b[32m    552\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "condition_embedding = ce.ConditionEmbedding(shared_embedding_holder, d, device=\"cuda\")\n",
    "\n",
    "condition_embeddings = condition_embedding(itd.conditions_batch)\n",
    "print(condition_embeddings)\n",
    "print(condition_embeddings.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
